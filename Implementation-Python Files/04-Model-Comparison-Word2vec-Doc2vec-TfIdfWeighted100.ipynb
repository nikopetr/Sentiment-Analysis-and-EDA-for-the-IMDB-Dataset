{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of Different Word Embeddings on Text Classification\n",
    "\n",
    "## Compared among word2vec, TF-IDF weighted, GloVe and doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:08.303434: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-31 13:51:08.303459: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "# Word2Vec libraries\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "# Gensim utils for glove2word2vec\n",
    "from gensim.test.utils import get_tmpfile, datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from collections import namedtuple, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Classifiers that are going to be used\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Evaluation metrics and reports\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Grid-search and crossvalidation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import timeit\n",
    "\n",
    "# NLP/language/string Imports\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "\n",
    "# Imports for files operations\n",
    "import os\n",
    "import pickle\n",
    "from numpy import genfromtxt # In order to load a .csv file to a numpy array object\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('max_colwidth',1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "VECTOR_SIZE = 100\n",
    "\n",
    "PICKLE_FILE = 'all_doc.pickle'\n",
    "WORD2VEC_FILE = \"word2vec_reviews_100.model\"\n",
    "MEAN_EMBEDDING_FILE = 'doc_vec_100.csv'\n",
    "TFIDF_EMBEDDING_FILE = 'tfidf_doc_vec_100.csv'\n",
    "GLOVE_EMBEDDING_FILE = 'glove_doc_vec_100.csv'\n",
    "DOC2VEC_EMBEDDING_FILE = 'dm_doc_vec_100.csv'\n",
    "\n",
    "random_state = 420\n",
    "\n",
    "# Specify train/valid/test sizes\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Incentive\n",
    "\n",
    "It's been a while not able to write new posts, so sad, but now finally I am back again to share some of the knowledge I've just acquired. This time is about NLP. \n",
    "\n",
    "As a fresh rookie in NLP, I'd like to play around and test out how different methods of creating doc vector perform on text classification. This post will be highly focused on feature engineering side, that is word vectorization, and less on modeling. Thus, without further due, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Introduction\n",
    "\n",
    "The word embeddings being investigated here are word2vec, TF-IDF weighted word2vec, pre-train GloVe word2vec and doc2vec. The packages needed are Gensim, Spacy and Scikit-Learn. Spacy is used in doc preprocessing, including stop word removal and custom token selection based on its part of speech. Gensim is heavily applied for training word2vec and doc2vec, and lastly, Scikit-Learn is for classifier building and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Summary\n",
    "\n",
    "After a series of comparison on different word embedding/averaging methods, it turns out that custom-trained word embedding and its averaging method, either simple mean or TF-IDF weighted has the best performance, while on the contrary, GloVe word embedding or custom-trained Doc2vec perform slightly worse than the former word embedding.\n",
    "\n",
    "Besides, even if we try to concatenate both word2vec and doc2vec as a whole feature set, it performs equally the same to just using averaging word embedding alone. In other words, no need to use both word2vec and doc2vec at the same time.\n",
    "\n",
    "\n",
    "| WordEmbedding Method        | F1 Score - Training | F1 Score - Testing | Accuracy - Training | Accuracy - Testing |\n",
    "| :---:                       | :---:               | :---:              | :---:               | :---:              |\n",
    "| Mean Word2vec               | 0.82                | 0.81               | 0.82                | 0.81               |\n",
    "| Tf-Idf Mean Word2vec        | 0.82                | 0.81               | 0.82                | 0.81               |\n",
    "| GloVe Mean Word2vec         | 0.72                | 0.71               | 0.73                | 0.72               |\n",
    "| PV-DM Doc2vec               | 0.79                | 0.78               | 0.79                | 0.78               |\n",
    "| Tf-Idf Word2vec + Doc2vec   | 0.84                | 0.81               | 0.85                | 0.82               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Credits to the Following Posts and Authors\n",
    "\n",
    "In creating my **python class object** used for text preprocessing, I referred from these well-written posts.\n",
    "\n",
    "* The post [\"Text Classification with Word2vec\"](http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/) by nadbor demos how to write your own class to compute average word embedding for doc, either simple averaging or TF-IDF weighted one.\n",
    "\n",
    "* [\"Multi-Class Text Classification Model Comparison and Selection\"](https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568) by Susan Li teaches me how to write beautiful averaging function for word embedding.\n",
    "\n",
    "* This tutorial [\"Gensim Doc2vec Tutorial on the IMDB Sentiment Dataset\"](https://github.com/RaRe-Technologies/gensim/blob/3c3506d51a2caf6b890de3b1b32a8b85f7566ca5/docs/notebooks/doc2vec-IMDB.ipynb) has step by step guidance on how to create doc2vec via Gensim.\n",
    "\n",
    "* [\"Distributed representations of sentences and documents\"](https://blog.acolyer.org/2016/06/01/distributed-representations-of-sentences-and-documents/) by Le & Mikolov presents a clear and easy-to-understand explanation on what's going under doc2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I am gonna use here is consumer complaints dataset on financial product/service as referred from [the post](https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4). The dataset is collected and published by [US GOV CFPB](https://catalog.data.gov/dataset/consumer-complaint-database), while we can also download the dataset from [Kaggle](https://www.kaggle.com/cfpb/us-consumer-finance-complaints).\n",
    "\n",
    "The original dataset contains more than 500 thousands records, and columns include product, sub_product, issue, consumer_complaint_narrative, and company_response_to_consumer etc.. We will just use **product** as text label and **consumer_complaint_narrative** as text itself. After dropping rows of missing values on consumer complaint we are left with around 60 thousands records. In order to lessen the computing pressure, I will just experiment on the first 25 thousands records only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file.\n",
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Familiar with Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get familiar with dataset.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not solely cooking (which would have been great too). Very stimulating and captivating, always keeping the viewer peeking around the corner to see what was coming up next. She is as down to earth and as personable as you get, like one of us which made the show all the more enjoyable. Special guests, who are friends as well made for a nice surprise too. Loved the 'first' theme and that the audience was invited to play along too. I must admit I was shocked to see her come in under her time limits on a few things, but she did it and by golly I'll be writing those recipes down. Saving time in the kitchen means more time with family. Those who haven't tuned in yet, find out what channel and the time, I assure you that you won't be disappointed.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          review  \\\n",
       "count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      50000   \n",
       "unique                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     49582   \n",
       "top     Loved today's show!!! It was a variety and not solely cooking (which would have been great too). Very stimulating and captivating, always keeping the viewer peeking around the corner to see what was coming up next. She is as down to earth and as personable as you get, like one of us which made the show all the more enjoyable. Special guests, who are friends as well made for a nice surprise too. Loved the 'first' theme and that the audience was invited to play along too. I must admit I was shocked to see her come in under her time limits on a few things, but she did it and by golly I'll be writing those recipes down. Saving time in the kitchen means more time with family. Those who haven't tuned in yet, find out what channel and the time, I assure you that you won't be disappointed.   \n",
       "freq                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           5   \n",
       "\n",
       "       sentiment  \n",
       "count      50000  \n",
       "unique         2  \n",
       "top     positive  \n",
       "freq       25000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49582</td>\n",
       "      <td>49582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>24884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         review  \\\n",
       "count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     49582   \n",
       "unique                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    49582   \n",
       "top     One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the...   \n",
       "freq                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1   \n",
       "\n",
       "       sentiment  \n",
       "count      49582  \n",
       "unique         2  \n",
       "top     positive  \n",
       "freq       24884  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select duplicate rows except first occurrence based on all columns\n",
    "df = df.drop_duplicates()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter on Text and Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>**Chart of Label Frequency**</mark>\n",
    "\n",
    "Now, let's see how frequency distributed among each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    24884\n",
       "negative    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of target variable.\n",
    "display(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>**Sample of Dataset**</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of review and its sentiment example...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case wi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the...   \n",
       "1   A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.   \n",
       "2                                                                           I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.   \n",
       "3                                                                                                                                                                                                                                                             Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case wi...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Demo of review and its sentiment example...')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the first step -Doc Preprocessing. Before we create our own word embedding based on the input texts, we need to preprocess the text so that it complies with the input format as Gensim requires. It involves multiple steps starting from word tokenization, bi-gram detection, lemmatization etc..\n",
    "\n",
    "Here, I wrote a python class called **DocProcess**. This class implements all the nitty-gritty jobs mentioned above for us under the hood, such as:\n",
    "\n",
    "1. First, the class takes in a series of texts, then tokenizes the text and removes all punctuations.\n",
    "\n",
    "2. It has the option build_bi, meaning whether to build up bi-gram, function adopted from Gensim. The default is False, if option build_bi is set to True, then the class will train a bi-gram detector and create bi-gram words for the text.\n",
    "\n",
    "3. Now, all the processed tokens are concatenated back to form a sentence again.\n",
    "\n",
    "4. The texts are tokenized once again, but this time, both **stop words** and **parts of speech** that are not allowed in the text will be removed and all tokens are **lemmatized**. These tokens are stored as `self.doc_words` - list of the tokens for each text(doc).\n",
    "\n",
    "5. Finally, these `self.doc_words` are wrapped up into **TaggedDocument**, a object type in Gensim for later use in doc2vec training. It's stored in `self.tagdocs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yourself', 'does', 'why', 'mightn', 'during', 'myself', 'theirs', 'by', 'y', 'few', 'at', 'for', 'on', \"she's\", 'shan', 'is', 'in', 'm', 'the', 'so', \"aren't\", 'nor', 'him', 'doing', 'of', 'and', 'he', \"shan't\", 'not', 'been', \"don't\", 'can', 'with', 'didn', 'isn', 'wouldn', 'very', 'ain', \"haven't\", \"mightn't\", 'wasn', 'be', 'it', 'you', 'her', 'but', \"should've\", 'too', 'from', 'as', 'some', 'herself', 'i', 't', 'hasn', 'out', 'those', 'about', 'needn', 'which', 'shouldn', 'off', 'after', 'me', 'only', 'than', 'over', 'all', 'did', 'each', \"that'll\", 'down', 'such', 'hadn', 'hers', 'under', 'itself', 'they', 'above', 'was', \"couldn't\", 'having', \"wasn't\", 'don', 'any', 'mustn', 'this', \"mustn't\", \"you'd\", 'then', 'doesn', 'while', 'because', 'here', 'into', \"isn't\", 'own', 'against', 'won', 'she', 'both', 'an', \"hadn't\", 'himself', 'their', 'these', 'we', 'where', 'what', 'further', \"shouldn't\", 'will', 'whom', 'once', 's', \"you're\", \"you'll\", \"wouldn't\", 'your', 'how', 've', 'between', 'that', 'below', \"won't\", 'just', 'a', 'do', 'ourselves', 'his', 'our', \"didn't\", 'has', 'being', \"doesn't\", 'have', 'ours', 'had', 'to', \"it's\", 'haven', 'or', 'before', 'more', 'o', 'again', 'now', \"you've\", 'll', 'am', 'them', 'yourselves', 'ma', 'should', 'through', 'until', 'were', \"needn't\", 'weren', 'its', 'there', 'up', 'most', 'themselves', 'no', 'couldn', 'my', \"hasn't\", \"weren't\", 'if', 'are', 'other', 'aren', 'd', 're', 'same', 'who', 'when', 'yours'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 190 reviews which include atleast one url\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.4024737926809745, pvalue=0.1607801273205851)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_url(text):\n",
    "\n",
    "# Regular expression for url\n",
    "\n",
    "    re_equ = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?]))\"\n",
    "\n",
    "    ck_url = re.findall(re_equ, text)\n",
    "\n",
    "    if ck_url:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "       \n",
    "\n",
    "df_temp = df.copy()\n",
    "df_temp['contains_url'] = df_temp['review'].apply(check_url)\n",
    "\n",
    "print(\"There are\", sum(df_temp['contains_url']), \"reviews which include atleast one url\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.barplot(x=\"sentiment\", y=\"contains_url\", data=df_temp)\n",
    "\n",
    "x_pos = df_temp[df_temp['sentiment'] == 'positive']['contains_url']\n",
    "x_neg = df_temp[df_temp['sentiment'] == 'negative']['contains_url']\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# two-side t-test with sample with identical means\n",
    "stats.ttest_ind(x_pos, x_neg,equal_var=False)\n",
    "# The t-test shows that a p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that our observation is not so unlikely to have occurred by chance. Therefore, we do not reject the null hypothesis of equal population means, and therefore since only a few reviews include links-urls it is not beneficial to keep a token for the urls in the tokenization process. \n",
    "# Thus, all urls will be thrown away during the pre-processing phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test shows that a p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that our observation is not so unlikely to have occurred by chance. Therefore, we do not reject the null hypothesis of equal population means, and therefore since only a few reviews include links-urls it is not beneficial to keep a token for the urls in the tokenization process. Thus, all urls will be thrown away during the pre-processing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle with the documents-reviews already exists\n"
     ]
    }
   ],
   "source": [
    "def expand_contractions(text):\n",
    "\treturn contractions.fix(text)\n",
    "\n",
    "class DocPreprocess(object):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t\t nlp,\n",
    "\t\t\t\t stop_words,\n",
    "\t\t\t\t docs,\n",
    "\t\t\t\t labels,\n",
    "\t\t\t\t build_bi=False,\n",
    "\t\t\t\t min_count=5,\n",
    "\t\t\t\t threshold=10,\n",
    "\t\t\t\t allowed_postags=['ADV', 'VERB', 'ADJ', 'NOUN', 'PROPN', 'NUM']):\n",
    "# \t\t\t\t not_allowed_postags = ['AUX', 'SCONJ', 'PUNCT', 'X', 'SYM'] # There are more\n",
    "\n",
    "\t\tself.nlp = nlp  # spacy nlp object\n",
    "\t\tself.stop_words = stop_words  # spacy.lang.en.stop_words.STOP_WORDS\n",
    "\t\tself.docs = docs  # docs must be list or series of documents\n",
    "\t\tself.labels = labels # labels must be list or or numpy array or series of labels\n",
    "\t\tself.doc_ids = np.arange(len(docs))\n",
    "\t\tself.parsed_docs = [BeautifulSoup(doc, \"html.parser\").get_text() for doc in self.docs] # Removes html tags\n",
    "\t\tself.parsed_docs = [re.sub(r'http\\S+', '', doc) for doc in self.parsed_docs] #remove urls\n",
    "\t\tself.parsed_docs = [re.sub(r'www.\\S+', '', doc) for doc in self.parsed_docs] #remove urls starting with 'www.'\n",
    "\t\tself.parsed_docs = [expand_contractions(doc) for doc in self.parsed_docs] # Expanding chatwords and contracts clearing contractions\n",
    "\t\t# This lowercases, tokenizes and remove words that their len is greater than 15 or lower than 2 (e.g. 'I')\n",
    "\t\tself.simple_doc_tokens = [gensim.utils.simple_preprocess(doc, deacc=True) for doc in self.parsed_docs]\n",
    "\n",
    "\t\tif build_bi:\n",
    "\t\t\tself.bi_detector = self.build_bi_detect(self.simple_doc_tokens, min_count=min_count, threshold=threshold)\n",
    "\t\t\tself.new_docs = self.make_bigram_doc(self.bi_detector, self.simple_doc_tokens)\n",
    "\t\telse:\n",
    "\t\t\tself.new_docs = self.make_simple_doc(self.simple_doc_tokens)\n",
    "\t\tself.doc_words = [self.lemmatize(doc, allowed_postags=allowed_postags) for doc in self.new_docs]\n",
    "\t\tself.tagdocs = [TaggedDocument(words=words, tags=[tag]) for words, tag in zip(self.doc_words, self.doc_ids)]\n",
    "\n",
    "\tdef build_bi_detect(self, simple_doc_tokens, min_count, threshold):\n",
    "\t\tbi_ = gensim.models.phrases.Phrases(simple_doc_tokens, min_count=min_count, threshold=threshold)\n",
    "\t\tbi_detector = gensim.models.phrases.Phraser(bi_)  # wrapper enhance efficiency\n",
    "\t\treturn bi_detector\n",
    "\n",
    "    \n",
    "\tdef make_simple_doc(self, simple_doc_tokens):\n",
    "\t\tsimple_docs = []\n",
    "\t\tfor doc_tokens in simple_doc_tokens:\n",
    "\t\t\tsimple = \" \".join(doc_tokens)  # concatenate back to a sentence\n",
    "\t\t\tsimple_docs.append(simple)\n",
    "\t\treturn simple_docs\n",
    "    \n",
    "\n",
    "\tdef make_bigram_doc(self, bi_detector, simple_doc_tokens):\n",
    "\t\tbi_doc_tokens = [bi_detector[doc_tokens] for doc_tokens in simple_doc_tokens]\n",
    "\t\tbi_docs = []\n",
    "\t\tfor bi_tokens in bi_doc_tokens:\n",
    "\t\t\tbi_doc = \" \".join(bi_tokens)  # concatenate back to a sentence\n",
    "\t\t\tbi_docs.append(bi_doc)\n",
    "\t\treturn bi_docs\n",
    "\n",
    "\n",
    "\tdef lemmatize(self, doc, allowed_postags):\n",
    "\t\t\"\"\"\n",
    "\t\tLemmatize words and remove stop_words.\n",
    "\t\t:param doc: text\n",
    "\t\t:param allowed_postags: list of pos tags\n",
    "\t\t:return:\n",
    "\t\t\tlist of tokens\n",
    "\t\t\"\"\"\n",
    "\t\tdoc = self.nlp(doc)\n",
    "\t\ttokens = [token.lemma_ for token in doc if (token.pos_ in allowed_postags) and (token.text not in self.stop_words)]\n",
    "\t\treturn tokens\n",
    "\n",
    "# DELETE THIS LINE \n",
    "# preprocessed_docs = DocPreprocess(nlp, stop_words, df['review'], df['sentiment'], build_bi=True)\n",
    "if not os.path.exists('./' + PICKLE_FILE):\n",
    "    preprocessed_docs = DocPreprocess(nlp, stop_words, df['review'], df['sentiment'], build_bi=True)\n",
    "else:\n",
    "    print(\"Pickle with the documents-reviews already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading documents from pickle\n"
     ]
    }
   ],
   "source": [
    "# Saving to pickle\n",
    "\n",
    "if os.path.exists('./' + PICKLE_FILE):\n",
    "    # Read the saved docs as a pickle.\n",
    "    print('Reading documents from pickle')\n",
    "    with open(os.path.join(PICKLE_FILE), 'rb') as f:\n",
    "        preprocessed_docs = pickle.load(f)\n",
    "else:  \n",
    "    # Save preprocessed_docs as a pickle.\n",
    "    print('Saving documents as a pickle')\n",
    "    with open(os.path.join(PICKLE_FILE), 'wb') as f:\n",
    "        pickle.dump(preprocessed_docs, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struacture of Preprocessed Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DocPreprocess"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of object preprocessed documents\n",
    "type(preprocessed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49582"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_docs.tagdocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tagged document object: \n",
      "TaggedDocument(['one', 'other_reviewer', 'mention', 'after_watche', 'episode', 'hook', 'right', 'happen', 'first', 'thing', 'struck_me', 'oz', 'brutality', 'unflinching', 'scene', 'violence', 'set', 'right', 'word', 'go', 'trust_me', 'show', 'faint_hearte', 'timid', 'show', 'pull', 'no_punche', 'regard', 'drug', 'sex', 'violence', 'hardcore', 'classic', 'use', 'word', 'call', 'oz', 'nickname', 'give', 'oswald', 'maximum_security', 'state', 'penitentary', 'focuses_mainly', 'experimental', 'section', 'prison', 'cell', 'glass', 'front', 'face', 'inwards', 'privacy', 'high', 'agenda', 'city', 'home', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'scuffle', 'death', 'stare', 'dodgy', 'dealing', 'shady', 'agreement', 'never', 'far_away', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'go', 'show', 'dare', 'forget', 'pretty', 'picture', 'paint', 'mainstream_audience', 'forget', 'charm', 'forget', 'romance', 'mess', 'first', 'episode', 'ever', 'see', 'struck_me', 'nasty', 'surreal', 'say', 'ready', 'watch', 'developed', 'taste', 'oz', 'get', 'accustomed', 'high', 'level', 'graphic_violence', 'violence', 'injustice', 'crooked', 'guard', 'sell', 'nickel', 'inmate', 'kill', 'order', 'get', 'away', 'well_mannere', 'middle_class', 'inmate', 'prison', 'bitch', 'due', 'lack', 'street', 'skill', 'prison', 'experience', 'watch', 'oz', 'become', 'comfortable', 'uncomfortable', 'view', 'get', 'touch', 'darker_side'], [0]) \n",
      "\n",
      "Words of the document:\n",
      "['one', 'other_reviewer', 'mention', 'after_watche', 'episode', 'hook', 'right', 'happen', 'first', 'thing', 'struck_me', 'oz', 'brutality', 'unflinching', 'scene', 'violence', 'set', 'right', 'word', 'go', 'trust_me', 'show', 'faint_hearte', 'timid', 'show', 'pull', 'no_punche', 'regard', 'drug', 'sex', 'violence', 'hardcore', 'classic', 'use', 'word', 'call', 'oz', 'nickname', 'give', 'oswald', 'maximum_security', 'state', 'penitentary', 'focuses_mainly', 'experimental', 'section', 'prison', 'cell', 'glass', 'front', 'face', 'inwards', 'privacy', 'high', 'agenda', 'city', 'home', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'scuffle', 'death', 'stare', 'dodgy', 'dealing', 'shady', 'agreement', 'never', 'far_away', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'go', 'show', 'dare', 'forget', 'pretty', 'picture', 'paint', 'mainstream_audience', 'forget', 'charm', 'forget', 'romance', 'mess', 'first', 'episode', 'ever', 'see', 'struck_me', 'nasty', 'surreal', 'say', 'ready', 'watch', 'developed', 'taste', 'oz', 'get', 'accustomed', 'high', 'level', 'graphic_violence', 'violence', 'injustice', 'crooked', 'guard', 'sell', 'nickel', 'inmate', 'kill', 'order', 'get', 'away', 'well_mannere', 'middle_class', 'inmate', 'prison', 'bitch', 'due', 'lack', 'street', 'skill', 'prison', 'experience', 'watch', 'oz', 'become', 'comfortable', 'uncomfortable', 'view', 'get', 'touch', 'darker_side'] \n",
      "\n",
      "Sentiment-label of tagged document: \n",
      "positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of a document\n",
    "doc_id = 0 # e.g. id = 3 \n",
    "\n",
    "print('A tagged document object: ')\n",
    "print(preprocessed_docs.tagdocs[doc_id], '\\n')\n",
    "\n",
    "print('Words of the document:')\n",
    "print(preprocessed_docs.doc_words[doc_id], '\\n')\n",
    "\n",
    "print('Sentiment-label of tagged document: ')\n",
    "print(preprocessed_docs.labels.iloc[doc_id], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the basic bow and TFidf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "# # Getting the features (tokens-words/ngrams)\n",
    "# X = preprocessed_docs.doc_words\n",
    "\n",
    "# # Labeling the sentient data\n",
    "# y = LabelBinarizer().fit_transform(df['sentiment']).ravel()\n",
    "\n",
    "# # Notice how we used stratification over the train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Disabling lowercase since the data was already lowercased\n",
    "# # Using deaful utf-8 encoding as it was mentioned in the lectures\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(analyzer=lambda x: x, lowercase=False, encoding='utf-8')\n",
    "\n",
    "# X_train_bow = vectorizer.fit_transform(X_train)\n",
    "# print('X_train_bow:', X_train_bow.shape)\n",
    "# X_test_bow = vectorizer.transform(X_test)\n",
    "# print('X_test_bow:', X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Training the model\n",
    "# lr_2 = LogisticRegression(penalty='l2', max_iter=500, random_state=random_state,verbose=10)\n",
    "\n",
    "# # Fitting the model for TF-IDFfrom sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Training the model\n",
    "# lr_1 = LogisticRegression(penalty='l2', max_iter=500, random_state=random_state)\n",
    "\n",
    "# # Fitting the model for Bag of words\n",
    "# lr_bow = lr_1.fit(X_train_bow, y_train)\n",
    "# # Predicting the test data for Bag of words\n",
    "# lr_bow_predict = lr_1.predict(X_test_bow)\n",
    "# # Accuracy score for bag of word\n",
    "# lr_bow_score = accuracy_score(y_test,lr_bow_predict)\n",
    "# print(\"lr_bow_score :\", lr_bow_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Disabling lowercase since the data was already lowercased\n",
    "# # Using deaful utf-8 encoding as it was mentioned in the lectures\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer(analyzer=lambda x: x, lowercase=False, encoding='utf-8')\n",
    "\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# print('X_train_tfidf:', X_train_tfidf.shape)\n",
    "# X_test_tfidf= vectorizer.transform(X_test)\n",
    "# print('X_test_tfidf:', X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Training the model\n",
    "# lr_2 = LogisticRegression(penalty='l2', max_iter=500, random_state=random_state,verbose=10)\n",
    "\n",
    "# # Fitting the model for TF-IDFfrom sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Training the model\n",
    "# lr_1 = LogisticRegression(penalty='l2', max_iter=500, random_state=random_state)\n",
    "\n",
    "# # Fitting the model for tfidf\n",
    "# lr_tfidf = lr_1.fit(X_train_tfidf, y_train)\n",
    "# # Predicting the test data for tf-idf\n",
    "# lr_tfidf_predict = lr_1.predict(X_test_tfidf)\n",
    "# # Accuracy score for tfidf\n",
    "# lr_tfidf_score = accuracy_score(y_test,lr_tfidf_predict)\n",
    "# print(\"lr_tfidf_score :\", lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal number of dimensions of word2vec models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build up Word Model - Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the text are properly processed, we're ready to train our word2vec via Gensim. Here I chose the dimension size 100 for each word embedding and window size of 5. The training iterates for 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpu cores to work: 7\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import sys\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "core_workers = multiprocessing.cpu_count() - 1 # Leave one core out\n",
    "print('Number of cpu cores to work: {}'.format(core_workers))\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be very slow otherwise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with the word2vec_reviews model already exists\n"
     ]
    }
   ],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after every epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "        self.start = timeit.default_timer()\n",
    "        self.stop = None\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        self.stop = timeit.default_timer()\n",
    "        print('Loss after epoch {}: {},  Epoch time: {} seconds'.format(self.epoch, loss_now, str(self.stop - self.start)))\n",
    "        self.epoch += 1\n",
    "        self.start = timeit.default_timer()\n",
    "\n",
    "\n",
    "if not os.path.exists('./' + WORD2VEC_FILE):\n",
    "    word_model = Word2Vec(preprocessed_docs.doc_words, min_count=2, vector_size=VECTOR_SIZE, window=5, workers=core_workers, epochs=175, \n",
    "                      compute_loss=True, callbacks=[callback()])\n",
    "else:\n",
    "    print(\"File with the word2vec_reviews model already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model from file\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Saving or loading word2vec model to/from a file\n",
    "\n",
    "if os.path.exists('./' + WORD2VEC_FILE):\n",
    "    # Read the saved model\n",
    "    print('Reading model from file')\n",
    "    try:\n",
    "        word_model = gensim.models.Word2Vec.load(WORD2VEC_FILE)\n",
    "        print('Done')\n",
    "    except Exception as e:    \n",
    "        print('Could not load file', e)\n",
    "else:  \n",
    "    # Save word2vec model object as a model file.\n",
    "    print('Saving documents as a pickle')\n",
    "    try:\n",
    "        word_model.save(WORD2VEC_FILE)\n",
    "        print('Done')\n",
    "    except Exception as e:\n",
    "        print('Could not save file', e)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging Word Embedding for Each Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Now we have the word embedding at hand, we'll be using the word embedding to compute for representative vector for whole text. It then serves as feature input for text classification model. There are various ways to come up with doc vector. First, let's start with the simple one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Averaging on Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rather straightforward method. It directly averages all word embedding occurred in the text. Here I adapted the code from these two posts [2](http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/), [3](https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568) and created the python class **MeanWordEmbeddingVectorizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with the average word2vec model already exists\n"
     ]
    }
   ],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "\n",
    "\tdef __init__(self, word_model):\n",
    "\t\tself.word_model = word_model\n",
    "\t\tself.vector_size = word_model.wv.vector_size\n",
    "\n",
    "\tdef fit(self):  # comply with scikit-learn transformer requirement\n",
    "\t\treturn self\n",
    "\n",
    "\tdef transform(self, docs):  # comply with scikit-learn transformer requirement\n",
    "\t\tdoc_word_vector = self.word_average_list(docs)\n",
    "\t\treturn doc_word_vector\n",
    "\n",
    "\tdef word_average(self, sent):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute average word vector for a single doc/sentence.\n",
    "\t\t:param sent: list of sentence tokens\n",
    "\t\t:return:\n",
    "\t\t\tmean: float of averaging word vectors\n",
    "\t\t\"\"\"\n",
    "\t\tmean = []\n",
    "\t\tfor word in sent:\n",
    "\t\t\tif word in self.word_model.wv:\n",
    "\t\t\t\tmean.append(self.word_model.wv.get_vector(word))\n",
    "\n",
    "\t\tif not mean:  # empty words\n",
    "\t\t\t# If a text is empty, return a vector of zeros.\n",
    "\t\t\tlogging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "\t\t\treturn np.zeros(self.vector_size)\n",
    "\t\telse:\n",
    "\t\t\tmean = np.array(mean).mean(axis=0)\n",
    "\t\t\treturn mean\n",
    "\n",
    "\n",
    "\tdef word_average_list(self, docs):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute average word vector for multiple docs, where docs had been tokenized.\n",
    "\t\t:param docs: list of sentence in list of separated tokens\n",
    "\t\t:return:\n",
    "\t\t\tarray of average word vector in shape (len(docs),)\n",
    "\t\t\"\"\"\n",
    "\t\treturn np.vstack([self.word_average(sent) for sent in docs])\n",
    "    \n",
    "    \n",
    "if not os.path.exists('./' + MEAN_EMBEDDING_FILE):\n",
    "    mean_vec_tr = MeanEmbeddingVectorizer(word_model)\n",
    "    doc_vec = mean_vec_tr.transform(preprocessed_docs.doc_words)\n",
    "else:\n",
    "    print(\"File with the average word2vec model already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model from file\n",
      "Done\n",
      "Shape of word-mean doc2vec: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49582, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving or loading averaging word2vec model to/from a file\n",
    "if os.path.exists('./' + MEAN_EMBEDDING_FILE):\n",
    "    # Read the saved model from a csv file\n",
    "    print('Reading model from file')\n",
    "    try:\n",
    "        doc_vec = genfromtxt(MEAN_EMBEDDING_FILE, delimiter=',')\n",
    "        print('Done')\n",
    "    except Exception as e:    \n",
    "        print('Could not load file', e)\n",
    "else:  \n",
    "    # Save model object as a csv file\n",
    "    print('Saving documents as a pickle')\n",
    "    try:\n",
    "        np.savetxt(os.path.join(MEAN_EMBEDDING_FILE), doc_vec, delimiter=',')\n",
    "        print('Done')\n",
    "    except Exception as e:\n",
    "        print('Could not save file', e)\n",
    "\n",
    "print('Shape of word-mean doc2vec: ')\n",
    "display(doc_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Weighted Averaging on Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not just satisfied with simple averaging? We can further adopt TF-IDF as weights for each word embedding. This will amplify the role of significant word in computing doc vector. Here, the whole process is implemented under class **TfidfEmbeddingVectorizer**. Again, the code is adapted from the same post source.\n",
    "\n",
    "One thing worth noted is that, the Term Frequency has already been considered when we conduct averaging over the text, but not Inverse Document Frequency, thus the weight literally being the IDF, and the unseen word is assigned the max IDF in default setting.\n",
    "\n",
    "And the other thing to note is that we need to fit the class with tokens first, for it must loop through all the words before hand in order to compute IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with the tf-idf word2vec model already exists\n"
     ]
    }
   ],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "\n",
    "\tdef __init__(self, word_model):\n",
    "\n",
    "\t\tself.word_model = word_model\n",
    "\t\tself.word_idf_weight = None\n",
    "\t\tself.vector_size = word_model.wv.vector_size\n",
    "\n",
    "\tdef fit(self, docs):  # comply with scikit-learn transformer requirement\n",
    "\t\t\"\"\"\n",
    "\t\tFit in a list of docs, which had been preprocessed and tokenized,\n",
    "\t\tsuch as word bi-grammed, stop-words removed, lemmatized, part of speech filtered.\n",
    "\t\tThen build up a tfidf model to compute each word's idf as its weight.\n",
    "\t\tNoted that tf weight is already involved when constructing average word vectors, and thus omitted.\n",
    "\t\t:param\n",
    "\t\t\tpre_processed_docs: list of docs, which are tokenized\n",
    "\t\t:return:\n",
    "\t\t\tself\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\ttext_docs = []\n",
    "\t\tfor doc in docs:\n",
    "\t\t\ttext_docs.append(\" \".join(doc))\n",
    "\n",
    "\t\ttfidf = TfidfVectorizer()\n",
    "\t\ttfidf.fit(text_docs)  # must be list of text string\n",
    "\n",
    "\t\t# if a word was never seen - it must be at least as infrequent\n",
    "\t\t# as any of the known words - so the default idf is the max of\n",
    "\t\t# known idf's\n",
    "\t\tmax_idf = max(tfidf.idf_)  # used as default value for defaultdict\n",
    "\t\tself.word_idf_weight = defaultdict(lambda: max_idf,\n",
    "\t\t\t\t\t\t\t\t\t\t   [(word, tfidf.idf_[i]) for word, i in tfidf.vocabulary_.items()])\n",
    "\t\treturn self\n",
    "\n",
    "\n",
    "\tdef transform(self, docs):  # comply with scikit-learn transformer requirement\n",
    "\t\tdoc_word_vector = self.word_average_list(docs)\n",
    "\t\treturn doc_word_vector\n",
    "\n",
    "\n",
    "\tdef word_average(self, sent):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute average word vector for a single doc/sentence.\n",
    "\t\t:param sent: list of sentence tokens\n",
    "\t\t:return:\n",
    "\t\t\tmean: float of averaging word vectors\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tmean = []\n",
    "\t\tfor word in sent:\n",
    "\t\t\tif word in self.word_model.wv.index_to_key:\n",
    "\t\t\t\tmean.append(self.word_model.wv.get_vector(word) * self.word_idf_weight[word])  # idf weighted\n",
    "\n",
    "\t\tif not mean:  # empty words\n",
    "\t\t\t# If a text is empty, return a vector of zeros.\n",
    "\t\t\tlogging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "\t\t\treturn np.zeros(self.vector_size)\n",
    "\t\telse:\n",
    "\t\t\tmean = np.array(mean).mean(axis=0)\n",
    "\t\t\treturn mean\n",
    "\n",
    "\n",
    "\tdef word_average_list(self, docs):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute average word vector for multiple docs, where docs had been tokenized.\n",
    "\t\t:param docs: list of sentence in list of separated tokens\n",
    "\t\t:return:\n",
    "\t\t\tarray of average word vector in shape (len(docs),)\n",
    "\t\t\"\"\"\n",
    "\t\treturn np.vstack([self.word_average(sent) for sent in docs])\n",
    "\n",
    "if not os.path.exists('./' + TFIDF_EMBEDDING_FILE):\n",
    "    tfidf_vec_tr = TfidfEmbeddingVectorizer(word_model)\n",
    "    tfidf_vec_tr.fit(preprocessed_docs.doc_words)  # fit tfidf model first\n",
    "    tfidf_doc_vec = tfidf_vec_tr.transform(preprocessed_docs.doc_words)\n",
    "else:\n",
    "    print(\"File with the tf-idf word2vec model already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model from file\n",
      "Done\n",
      "Shape of tf-idf doc2vec: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49582, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving or loading tf-idf word2vec model to/from a file\n",
    "if os.path.exists('./' + TFIDF_EMBEDDING_FILE):\n",
    "    # Read the saved model from a csv file\n",
    "    print('Reading model from file')\n",
    "    try:\n",
    "        tfidf_doc_vec = genfromtxt(TFIDF_EMBEDDING_FILE, delimiter=',')\n",
    "        print('Done')\n",
    "    except Exception as e:    \n",
    "        print('Could not load file', e)\n",
    "else:  \n",
    "    # Save model object as a csv file\n",
    "    print('Saving documents as a pickle')\n",
    "    try:\n",
    "        np.savetxt(os.path.join(TFIDF_EMBEDDING_FILE), tfidf_doc_vec, delimiter=',')\n",
    "        print('Done')\n",
    "    except Exception as e:\n",
    "        print('Could not save file', e)\n",
    "\n",
    "print('Shape of tf-idf doc2vec: ')\n",
    "display(tfidf_doc_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage Pre-train GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in GloVe Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's include another option-leveraging the existing pre-trained word embedding and see how it performs in text classification. Here I follow up the instructions from [Stanford NLP course(CS224N) notebook](http://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html), importing GloVe word embedding into Gensim to compute for averaging word embedding on text.\n",
    "\n",
    "As a side note, I've also tried to apply Tf-IDF weighted method on GloVe vector, but found out that the result is basically the same as the ones from TF-IDF weighted averaging doc vector. Thus, I omit the demonstration and just include simple averaging on GloVe word vector here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>**APPENDIX: The explanation for logic behind loading pre-train word vector.**</mark>\n",
    "\n",
    "The result of `datapath()` shows that Gensim will try to load in dataset from */Users/XXX/miniconda3/lib/python3.7/site-packages/gensim/test/test_data/*, and calls it `glove_vec_fi`.\n",
    "\n",
    "It then uses `get_tmpfile()` to create a temporary file path to store the word2vec `tmp_word2vec_fi`, which is converted from `glove_vec_fi`.\n",
    "\n",
    "At the final step, **KeyedVectors** then loads in the `tmp_word2vec_fi` as word model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Averaging on GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with the average word2vec GloVe model already exists\n"
     ]
    }
   ],
   "source": [
    "class MeanEmbeddingVectorizerGlove(MeanEmbeddingVectorizer):\n",
    "\n",
    "\tdef __init__(self, word_model):\n",
    "\t\tself.word_model = word_model\n",
    "\t\tself.vector_size = word_model.vector_size\n",
    "\n",
    "\tdef word_average(self, sent):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute average word vector for a single doc/sentence.\n",
    "\t\t:param sent: list of sentence tokens\n",
    "\t\t:return:\n",
    "\t\t\tmean: float of averaging word vectors\n",
    "\t\t\"\"\"\n",
    "\t\tmean = []\n",
    "\t\tfor word in sent:\n",
    "\t\t\tif word in self.word_model:\n",
    "\t\t\t\tmean.append(self.word_model.get_vector(word))\n",
    "\n",
    "\t\tif not mean:  # empty words\n",
    "\t\t\t# If a text is empty, return a vector of zeros.\n",
    "\t\t\tlogging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "\t\t\treturn np.zeros(self.vector_size)\n",
    "\t\telse:\n",
    "\t\t\tmean = np.array(mean).mean(axis=0)\n",
    "\t\t\treturn mean\n",
    "\n",
    "\n",
    "# Load in GloVe vector.\n",
    "if not os.path.exists('./' + GLOVE_EMBEDDING_FILE):\n",
    "    glove_vec_fi = datapath('/home/nick/PycharmProjects/pythonProject/Homework/glove_emb/glove.6B.100d.txt')\n",
    "    tmp_word2vec_fi = get_tmpfile('tmp_glove2word2vec.txt')\n",
    "\n",
    "    glove2word2vec(glove_vec_fi, tmp_word2vec_fi)\n",
    "\n",
    "    glove_word_model = KeyedVectors.load_word2vec_format(tmp_word2vec_fi)\n",
    "\n",
    "    # Apply word averaging on GloVe word vector.\n",
    "    glove_mean_vec_tr = MeanEmbeddingVectorizerGlove(glove_word_model)\n",
    "    glove_doc_vec = glove_mean_vec_tr.transform(preprocessed_docs.doc_words)\n",
    "else:\n",
    "    print(\"File with the average word2vec GloVe model already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model from file\n",
      "Done\n",
      "Shape of mean glove_doc_vec: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49582, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving or loading averaging glove model to/from a file\n",
    "if os.path.exists('./' + GLOVE_EMBEDDING_FILE):\n",
    "    # Read the saved model from a csv file\n",
    "    print('Reading model from file')\n",
    "    try:\n",
    "        glove_doc_vec = genfromtxt(GLOVE_EMBEDDING_FILE, delimiter=',')\n",
    "        print('Done')\n",
    "    except Exception as e:    \n",
    "        print('Could not load file', e)\n",
    "else:  \n",
    "    # Save model object as a csv file\n",
    "    print('Saving documents as a csv')\n",
    "    try:\n",
    "        np.savetxt(os.path.join(GLOVE_EMBEDDING_FILE), glove_doc_vec, delimiter=',')\n",
    "        print('Done')\n",
    "    except Exception as e:\n",
    "        print('Could not save file', e)\n",
    "\n",
    "print('Shape of mean glove_doc_vec: ')\n",
    "display(glove_doc_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examine if glove_doc_vec is equal to self-trained doc_vec...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine if glove_doc_vec is equal to self-trained doc_vec.\n",
    "print('Examine if glove_doc_vec is equal to self-trained doc_vec...')\n",
    "glove_doc_vec[4] == doc_vec[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Doc2vec Training Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PV-DM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, we still have one more option-to directly train doc2vec, and no need to average all word embeddings. Here I chose **PV-DM model** to train my doc2vec.\n",
    "\n",
    "The script is mostly referred from [Gensim tutorial](https://github.com/RaRe-Technologies/gensim/blob/3c3506d51a2caf6b890de3b1b32a8b85f7566ca5/docs/notebooks/doc2vec-IMDB.ipynb). And again, to save all the labor, I create a class **DocModel** for it. The class just needs to take in the **TaggedDocument** and then we call `self.custom_train()` method, the doc model will train itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>**APPENDIX: Training with Fixed Learning Rate.**</mark>\n",
    "\n",
    "It's said to achieve better result, but the statement is from a rather old-version gensim tutorial. I found no better training result out of using fixed learning rate. Instead, using the default one, which is also recommended by the new gensim document achieving better performance.\n",
    "\n",
    "Excerpted from [Doc2vec tutorial](https://rare-technologies.com/doc2vec-tutorial/)\n",
    "\n",
    "I have obtained better results by iterating over the data several times and either\n",
    "\n",
    "1. randomizing the order of input sentences, or\n",
    "2. manually controlling the learning rate over the course of several iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocModel(object):\n",
    "\n",
    "\tdef __init__(self, docs, **kwargs):\n",
    "\t\t\"\"\"\n",
    "\t\t:param docs: list of TaggedDocument\n",
    "\t\t:param kwargs: dictionary of (key,value) for Doc2Vec arguments\n",
    "\t\t\"\"\"\n",
    "\t\tself.model = Doc2Vec(**kwargs)\n",
    "\t\tself.docs = docs\n",
    "\t\tself.model.build_vocab([x for x in self.docs])\n",
    "\n",
    "\tdef custom_train(self, fixed_lr=False, fixed_lr_epochs=None):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain Doc2Vec with two options, without fixed learning rate(recommended) or with fixed learning rate.\n",
    "\t\tFixed learning rate also includes implementation of shuffling training dataset.\n",
    "\t\t:param fixed_lr: boolean\n",
    "\t\t:param fixed_lr_epochs: num of epochs for fixed lr training\n",
    "\t\t\"\"\"\n",
    "\t\tif not fixed_lr:\n",
    "\t\t\tself.model.train([x for x in self.docs],\n",
    "\t\t\t\t\t\t\t total_examples=len(self.docs),\n",
    "\t\t\t\t\t\t\t epochs=self.model.epochs)\n",
    "\t\telse:\n",
    "\t\t\tfor _ in range(fixed_lr_epochs):\n",
    "\t\t\t\tself.model.train(utils.shuffle([x for x in self.docs]),\n",
    "\t\t\t\t\t\t\t\t total_examples=len(self.docs),\n",
    "\t\t\t\t\t\t\t\t epochs=1)\n",
    "\t\t\t\tself.model.alpha -= 0.002\n",
    "\t\t\t\tself.model.min_alpha = self.model.alpha  # fixed learning rate\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with the doc2vec model already exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./' + DOC2VEC_EMBEDDING_FILE):\n",
    "\n",
    "    # Instantiate a pv-dm model\n",
    "    # Configure keyed arguments for Doc2Vec model.\n",
    "    dm_args = {\n",
    "        'dm': 1,\n",
    "        'dm_mean': 1,\n",
    "        'vector_size': 100, # VECTOR_SIZE IMPORTANT!!!\n",
    "        'window': 5,\n",
    "        'negative': 5,\n",
    "        'hs': 0,\n",
    "        'min_count': 2,\n",
    "        'sample': 0,\n",
    "        'workers': 7-1,\n",
    "        'alpha': 0.025,\n",
    "        'min_alpha': 0.025,\n",
    "        'epochs': 175,\n",
    "        'comment': 'alpha=0.025'\n",
    "    }\n",
    "    dm = DocModel(docs=preprocessed_docs.tagdocs, **dm_args)\n",
    "    dm.custom_train()\n",
    "\n",
    "    # Save doc2vec as feature dataframe.\n",
    "    dm_doc_vec_ls = []\n",
    "    for i in range(len(dm.model.docvecs)):\n",
    "        dm_doc_vec_ls.append(dm.model.docvecs[i])\n",
    "\n",
    "    dm_doc_vec = pd.DataFrame(dm_doc_vec_ls)\n",
    "else:\n",
    "    print(\"File with the doc2vec model already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading doc2vec model from file\n",
      "Done\n",
      "Shape of doc2vec: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49582, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving or loading doc2vec model to/from a file\n",
    "if os.path.exists('./' + DOC2VEC_EMBEDDING_FILE):\n",
    "    # Read the saved model from a csv file\n",
    "    print('Reading doc2vec model from file')\n",
    "    try:\n",
    "        dm_doc_vec = pd.read_csv(os.path.join(DOC2VEC_EMBEDDING_FILE), header=None)\n",
    "        print('Done')\n",
    "    except Exception as e:    \n",
    "        print('Could not load file', e)\n",
    "else:  \n",
    "    # Save model object as a csv file\n",
    "    print('Saving documents as a csv')\n",
    "    try:\n",
    "        dm_doc_vec.to_csv(os.path.join(DOC2VEC_EMBEDDING_FILE), index=False, header=False)\n",
    "        print('Done')\n",
    "    except Exception as e:\n",
    "        print('Could not save file', e)\n",
    "\n",
    "print('Shape of doc2vec: ')\n",
    "display(dm_doc_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've prepared all the necessary ingredients-different types of features. Let's experiment to observe their effect on classification performance. Here, I'll use **basic logistic model** as the base model and feed in different kind of features created earlier. Hence, to compare their effectiveness.\n",
    "\n",
    "In addition to compare effects of each word embedding averaging method, I also try to **concatenate word2vec and doc2vec** together, and see if it can boost up the performance even more.\n",
    "\n",
    "I used TF-IDF weighted word embedding and PV-DM doc2vec together. The result shows that it increases the accuracy on training dataset (perhaps a sign of over-fitting?), but not so significant improvement on testing dataset compared using TF-IDF word2vec alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target_labels\n",
    "target_labels = preprocessed_docs.labels\n",
    "\n",
    "# doc_vec = pd.read_csv(os.path.join(MEAN_EMBEDDING_FILE), header=None)\n",
    "tfidf_doc_vec = pd.read_csv(os.path.join(TFIDF_EMBEDDING_FILE), header=None)\n",
    "# glove_doc_vec = pd.read_csv(os.path.join(GLOVE_EMBEDDING_FILE), header=None)\n",
    "dm_doc_vec = pd.read_csv(os.path.join(DOC2VEC_EMBEDDING_FILE), header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification via Logistic Model\n",
    "# logistic = LogisticRegression(random_state=random_state, multi_class='multinomial', solver='saga')\n",
    "logistic = LogisticRegression(penalty='l2', max_iter=500, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_data_splits(df, concat_dfs=None):\n",
    "    if concat_dfs is not None:\n",
    "        for concat_df in concat_dfs:\n",
    "            df = pd.concat([df, concat_df], axis=1, ignore_index=True)\n",
    "    \n",
    "    # Prepare test dataset\n",
    "    train_X, test_X, train_y, test_y = train_test_split(df,\n",
    "                                                    target_labels,\n",
    "                                                    test_size=TEST_SIZE,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=target_labels)\n",
    "    # Prepare valid dataset\n",
    "    if VALID_SIZE != 0:\n",
    "        train_X, valid_X, train_y, valid_y = train_test_split(train_X,\n",
    "                                                      train_y,\n",
    "                                                      test_size=VALID_SIZE,\n",
    "                                                      random_state=random_state,\n",
    "                                                      stratify=train_y)\n",
    "    \n",
    "    print('Shape of train_X: {}'.format(train_X.shape))\n",
    "    print('Shape of valid_X: {}'.format(valid_X.shape if 'valid_X' in vars() else (0,0)))\n",
    "    print('Shape of text_X: {}'.format(test_X.shape))\n",
    "    \n",
    "    if VALID_SIZE != 0:\n",
    "        return train_X, valid_X, test_X, train_y, valid_y, test_y\n",
    "    else:\n",
    "        return train_X, None, test_X, train_y, None, test_y\n",
    "    \n",
    "def evaluate_model(model, feature, label, label_names):\n",
    "\tpred = model.predict(feature)\n",
    "\ttrue = np.array(label)\n",
    "\n",
    "\tprint('Score on dataset...\\n')\n",
    "\tprint('Confusion Matrix:\\n', confusion_matrix(true, pred))\n",
    "\tprint('\\nClassification Report:\\n', classification_report(true, pred, target_names=label_names))\n",
    "\tprint('\\naccuracy: {:.3f}'.format(accuracy_score(true, pred)))\n",
    "\tprint('f1 score: {:.3f}'.format(f1_score(true, pred, average='weighted')))\n",
    "\n",
    "\treturn pred, true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Simple Averaging Word Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic  # or choose sgd.\n",
    "df = doc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (39665, 100)\n",
      "Shape of valid_X: (0, 0)\n",
      "Shape of text_X: (9917, 100)\n",
      "Training time1.733488825004315 seconds\n"
     ]
    }
   ],
   "source": [
    "# __init_model_data_splits__\n",
    "train_X, valid_X, test_X, train_y, valid_y, test_y = init_data_splits(df)\n",
    "\n",
    "    \n",
    "start = timeit.default_timer()\n",
    "clf = model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Mean Word Vector on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17342  2416]\n",
      " [ 2312 17595]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88     19758\n",
      "    positive       0.88      0.88      0.88     19907\n",
      "\n",
      "    accuracy                           0.88     39665\n",
      "   macro avg       0.88      0.88      0.88     39665\n",
      "weighted avg       0.88      0.88      0.88     39665\n",
      "\n",
      "\n",
      "accuracy: 0.881\n",
      "f1 score: 0.881\n"
     ]
    }
   ],
   "source": [
    "# Score on valid dataset.\n",
    "print('Performance of Mean Word Vector on training dataset...')\n",
    "_, _ = evaluate_model(clf, train_X, train_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Mean Word Vector on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4301  639]\n",
      " [ 551 4426]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88      4940\n",
      "    positive       0.87      0.89      0.88      4977\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n",
      "\n",
      "accuracy: 0.880\n",
      "f1 score: 0.880\n"
     ]
    }
   ],
   "source": [
    "# Score on test dataset.\n",
    "print('Performance of Mean Word Vector on testing dataset...')\n",
    "_, _ = evaluate_model(clf, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Tf-Idf Weighted Averaging Word Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic  # or choose sgd.\n",
    "df = tfidf_doc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (39665, 100)\n",
      "Shape of valid_X: (0, 0)\n",
      "Shape of text_X: (9917, 100)\n",
      "Training time0.9677956239902414 seconds\n"
     ]
    }
   ],
   "source": [
    "# __init_model_data_splits__\n",
    "train_X, valid_X, test_X, train_y, valid_y, test_y = init_data_splits(df)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "clf = model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time{} seconds'.format(str(stop - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Tf-Idf Mean Word Vector on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17302  2456]\n",
      " [ 2424 17483]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88     19758\n",
      "    positive       0.88      0.88      0.88     19907\n",
      "\n",
      "    accuracy                           0.88     39665\n",
      "   macro avg       0.88      0.88      0.88     39665\n",
      "weighted avg       0.88      0.88      0.88     39665\n",
      "\n",
      "\n",
      "accuracy: 0.877\n",
      "f1 score: 0.877\n"
     ]
    }
   ],
   "source": [
    "# Score on valid dataset.\n",
    "print('Performance of Tf-Idf Mean Word Vector on training dataset...')\n",
    "_, _ = evaluate_model(clf, train_X, train_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Tf-Idf Mean Word Vector on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4286  654]\n",
      " [ 555 4422]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88      4940\n",
      "    positive       0.87      0.89      0.88      4977\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n",
      "\n",
      "accuracy: 0.878\n",
      "f1 score: 0.878\n"
     ]
    }
   ],
   "source": [
    "# Score on test dataset.\n",
    "print('Performance of Tf-Idf Mean Word Vector on testing dataset...')\n",
    "_, _ = evaluate_model(clf, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Simple Averaging of GloVe Word Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic  # or choose sgd.\n",
    "df = glove_doc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (39665, 100)\n",
      "Shape of valid_X: (0, 0)\n",
      "Shape of text_X: (9917, 100)\n",
      "Training time2.1632792220043484 seconds\n"
     ]
    }
   ],
   "source": [
    "# __init_model_data_splits__\n",
    "train_X, valid_X, test_X, train_y, valid_y, test_y = init_data_splits(df)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "clf = model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time{} seconds'.format(str(stop - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of GloVe Mean Word Vector on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15651  4107]\n",
      " [ 4056 15851]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.79      0.79     19758\n",
      "    positive       0.79      0.80      0.80     19907\n",
      "\n",
      "    accuracy                           0.79     39665\n",
      "   macro avg       0.79      0.79      0.79     39665\n",
      "weighted avg       0.79      0.79      0.79     39665\n",
      "\n",
      "\n",
      "accuracy: 0.794\n",
      "f1 score: 0.794\n"
     ]
    }
   ],
   "source": [
    "# Score on valid dataset.\n",
    "print('Performance of GloVe Mean Word Vector on training dataset...')\n",
    "_, _ = evaluate_model(clf, train_X, train_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of GloVe Mean Word Vector on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3898 1042]\n",
      " [ 976 4001]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.79      0.79      4940\n",
      "    positive       0.79      0.80      0.80      4977\n",
      "\n",
      "    accuracy                           0.80      9917\n",
      "   macro avg       0.80      0.80      0.80      9917\n",
      "weighted avg       0.80      0.80      0.80      9917\n",
      "\n",
      "\n",
      "accuracy: 0.797\n",
      "f1 score: 0.796\n"
     ]
    }
   ],
   "source": [
    "# Score on test dataset.\n",
    "print('Performance of GloVe Mean Word Vector on testing dataset...')\n",
    "_, _ = evaluate_model(clf, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on PV-DM Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic  # or choose sgd.\n",
    "df = dm_doc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (39665, 100)\n",
      "Shape of valid_X: (0, 0)\n",
      "Shape of text_X: (9917, 100)\n",
      "Training time0.5052957300067646 seconds\n"
     ]
    }
   ],
   "source": [
    "# __init_model_data_splits__\n",
    "train_X, valid_X, test_X, train_y, valid_y, test_y = init_data_splits(df)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "clf = model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time{} seconds'.format(str(stop - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Doc2vec on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17251  2507]\n",
      " [ 2616 17291]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87     19758\n",
      "    positive       0.87      0.87      0.87     19907\n",
      "\n",
      "    accuracy                           0.87     39665\n",
      "   macro avg       0.87      0.87      0.87     39665\n",
      "weighted avg       0.87      0.87      0.87     39665\n",
      "\n",
      "\n",
      "accuracy: 0.871\n",
      "f1 score: 0.871\n"
     ]
    }
   ],
   "source": [
    "# Score on valid dataset.\n",
    "print('Performance of Doc2vec on training dataset...')\n",
    "_, _ = evaluate_model(clf, train_X, train_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Doc2vec on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4299  641]\n",
      " [ 633 4344]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87      4940\n",
      "    positive       0.87      0.87      0.87      4977\n",
      "\n",
      "    accuracy                           0.87      9917\n",
      "   macro avg       0.87      0.87      0.87      9917\n",
      "weighted avg       0.87      0.87      0.87      9917\n",
      "\n",
      "\n",
      "accuracy: 0.872\n",
      "f1 score: 0.872\n"
     ]
    }
   ],
   "source": [
    "# Score on test dataset.\n",
    "print('Performance of Doc2vec on testing dataset...')\n",
    "_, _ = evaluate_model(clf, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Tf-Idf and Doc2vec Concatenated Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic  # or choose sgd.\n",
    "df = tfidf_doc_vec\n",
    "concat_dfs = [dm_doc_vec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (39665, 200)\n",
      "Shape of valid_X: (0, 0)\n",
      "Shape of text_X: (9917, 200)\n",
      "Training time2.317206299994723 seconds\n"
     ]
    }
   ],
   "source": [
    "train_X, valid_X, test_X, train_y, valid_y, test_y = init_data_splits(df, concat_dfs=concat_dfs)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "clf = model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time{} seconds'.format(str(stop - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Tf-Idf+Doc2vec on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17634  2124]\n",
      " [ 2140 17767]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89     19758\n",
      "    positive       0.89      0.89      0.89     19907\n",
      "\n",
      "    accuracy                           0.89     39665\n",
      "   macro avg       0.89      0.89      0.89     39665\n",
      "weighted avg       0.89      0.89      0.89     39665\n",
      "\n",
      "\n",
      "accuracy: 0.892\n",
      "f1 score: 0.892\n"
     ]
    }
   ],
   "source": [
    "# Score on valid dataset.\n",
    "print('Performance of Tf-Idf+Doc2vec on training dataset...')\n",
    "_, _ = evaluate_model(clf, train_X, train_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score on test dataset.\n",
    "print('Performance of Tf-Idf+Doc2vec on testing dataset...')\n",
    "_, _ = evaluate_model(clf, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-Search for Best Hyper-Paremeters for the tfidf + doc2vec approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (39665, 200)\n",
      "Shape of valid_X: (0, 0)\n",
      "Shape of text_X: (9917, 200)\n"
     ]
    }
   ],
   "source": [
    "# Using the tfidf + doc_vec approach\n",
    "\n",
    "df = tfidf_doc_vec\n",
    "concat_dfs = [dm_doc_vec]\n",
    "train_X, valid_X, test_X, train_y, valid_y, test_y = init_data_splits(df, concat_dfs=concat_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Parameters on L2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END .......C=0.001;, score=(train=0.892, test=0.890) total time=   1.4s\n",
      "[CV 2/5] END .......C=0.001;, score=(train=0.892, test=0.888) total time=   1.1s\n",
      "[CV 3/5] END .......C=0.001;, score=(train=0.893, test=0.886) total time=   1.1s\n",
      "[CV 4/5] END .......C=0.001;, score=(train=0.892, test=0.892) total time=   1.2s\n",
      "[CV 5/5] END .......C=0.001;, score=(train=0.891, test=0.893) total time=   1.2s\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.892, test=0.891) total time=   1.6s\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.893, test=0.888) total time=   2.1s\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.893, test=0.885) total time=   1.9s\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.893, test=0.891) total time=   1.8s\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.892, test=0.893) total time=   1.6s\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.893, test=0.891) total time=   2.1s\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.893, test=0.887) total time=   1.8s\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.893, test=0.885) total time=   1.8s\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.893, test=0.891) total time=   1.8s\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.892, test=0.893) total time=   2.2s\n",
      "[CV 1/5] END ...........C=1;, score=(train=0.892, test=0.891) total time=   2.0s\n",
      "[CV 2/5] END ...........C=1;, score=(train=0.893, test=0.887) total time=   2.0s\n",
      "[CV 3/5] END ...........C=1;, score=(train=0.893, test=0.886) total time=   2.0s\n",
      "[CV 4/5] END ...........C=1;, score=(train=0.893, test=0.891) total time=   2.1s\n",
      "[CV 5/5] END ...........C=1;, score=(train=0.893, test=0.893) total time=   2.2s\n",
      "[CV 1/5] END ..........C=10;, score=(train=0.892, test=0.891) total time=   2.5s\n",
      "[CV 2/5] END ..........C=10;, score=(train=0.893, test=0.887) total time=   1.8s\n",
      "[CV 3/5] END ..........C=10;, score=(train=0.893, test=0.885) total time=   1.8s\n",
      "[CV 4/5] END ..........C=10;, score=(train=0.893, test=0.892) total time=   2.0s\n",
      "[CV 5/5] END ..........C=10;, score=(train=0.893, test=0.893) total time=   2.0s\n",
      "[CV 1/5] END .........C=100;, score=(train=0.892, test=0.891) total time=   2.0s\n",
      "[CV 2/5] END .........C=100;, score=(train=0.893, test=0.887) total time=   2.6s\n",
      "[CV 3/5] END .........C=100;, score=(train=0.893, test=0.885) total time=   2.0s\n",
      "[CV 4/5] END .........C=100;, score=(train=0.893, test=0.891) total time=   1.8s\n",
      "[CV 5/5] END .........C=100;, score=(train=0.892, test=0.893) total time=   2.1s\n",
      "Training time 60.34931083900119 seconds\n",
      "The best Accuracy of all model parameters' combination on model: 0.8898\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.154587</td>\n",
       "      <td>0.036490</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.892077</td>\n",
       "      <td>0.889752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.040528</td>\n",
       "      <td>0.036530</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.892651</td>\n",
       "      <td>0.889726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.978887</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.892638</td>\n",
       "      <td>0.889651</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.761858</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.889651</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.898160</td>\n",
       "      <td>0.037305</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.892613</td>\n",
       "      <td>0.889626</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.062070</td>\n",
       "      <td>0.037295</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.892626</td>\n",
       "      <td>0.889575</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time        params  mean_train_score  \\\n",
       "0       1.154587         0.036490  {'C': 0.001}          0.892077   \n",
       "3       2.040528         0.036530      {'C': 1}          0.892651   \n",
       "4       1.978887         0.036607     {'C': 10}          0.892638   \n",
       "1       1.761858         0.037291   {'C': 0.01}          0.892493   \n",
       "2       1.898160         0.037305    {'C': 0.1}          0.892613   \n",
       "5       2.062070         0.037295    {'C': 100}          0.892626   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "0         0.889752                1  \n",
       "3         0.889726                2  \n",
       "4         0.889651                3  \n",
       "1         0.889651                4  \n",
       "2         0.889626                5  \n",
       "5         0.889575                6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 1.5875357750010153 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17614  2144]\n",
      " [ 2150 17757]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89     19758\n",
      "    positive       0.89      0.89      0.89     19907\n",
      "\n",
      "    accuracy                           0.89     39665\n",
      "   macro avg       0.89      0.89      0.89     39665\n",
      "weighted avg       0.89      0.89      0.89     39665\n",
      "\n",
      "\n",
      "accuracy: 0.892\n",
      "f1 score: 0.892\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4363  577]\n",
      " [ 495 4482]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      4940\n",
      "    positive       0.89      0.90      0.89      4977\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n",
      "\n",
      "accuracy: 0.892\n",
      "f1 score: 0.892\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(penalty='l2', max_iter=500, random_state=random_state)\n",
    "params_log = {\"C\": [0.001,0.01,0.1,1,10,100]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Parameters on L1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END .......C=0.001;, score=(train=0.877, test=0.876) total time=   2.3s\n",
      "[CV 2/5] END .......C=0.001;, score=(train=0.878, test=0.872) total time=   2.9s\n",
      "[CV 3/5] END .......C=0.001;, score=(train=0.877, test=0.874) total time=   2.3s\n",
      "[CV 4/5] END .......C=0.001;, score=(train=0.875, test=0.878) total time=   3.0s\n",
      "[CV 5/5] END .......C=0.001;, score=(train=0.877, test=0.875) total time=   2.0s\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.892, test=0.887) total time=  14.5s\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.892, test=0.887) total time=  17.6s\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.892, test=0.886) total time=  16.2s\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.890, test=0.891) total time=  19.7s\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.890, test=0.892) total time=  18.4s\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.892, test=0.890) total time=  40.0s\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.893, test=0.888) total time=  36.8s\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.893, test=0.885) total time=  37.7s\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.892, test=0.891) total time=  38.8s\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.892, test=0.893) total time=  39.6s\n",
      "[CV 1/5] END ...........C=1;, score=(train=0.892, test=0.891) total time=  38.4s\n",
      "[CV 2/5] END ...........C=1;, score=(train=0.893, test=0.888) total time=  37.8s\n",
      "[CV 3/5] END ...........C=1;, score=(train=0.893, test=0.885) total time=  37.9s\n",
      "[CV 4/5] END ...........C=1;, score=(train=0.892, test=0.892) total time=  37.0s\n",
      "[CV 5/5] END ...........C=1;, score=(train=0.892, test=0.893) total time=  36.2s\n",
      "[CV 1/5] END ..........C=10;, score=(train=0.892, test=0.891) total time=  36.2s\n",
      "[CV 2/5] END ..........C=10;, score=(train=0.893, test=0.889) total time=  36.4s\n",
      "[CV 3/5] END ..........C=10;, score=(train=0.893, test=0.885) total time=  36.4s\n",
      "[CV 4/5] END ..........C=10;, score=(train=0.892, test=0.892) total time=  35.9s\n",
      "[CV 5/5] END ..........C=10;, score=(train=0.892, test=0.893) total time=  36.2s\n",
      "[CV 1/5] END .........C=100;, score=(train=0.892, test=0.891) total time=  36.8s\n",
      "[CV 2/5] END .........C=100;, score=(train=0.893, test=0.889) total time=  36.7s\n",
      "[CV 3/5] END .........C=100;, score=(train=0.893, test=0.885) total time=  36.4s\n",
      "[CV 4/5] END .........C=100;, score=(train=0.892, test=0.892) total time=  36.8s\n",
      "[CV 5/5] END .........C=100;, score=(train=0.892, test=0.893) total time=  37.0s\n",
      "Training time 893.1517040210001 seconds\n",
      "The best Accuracy of all model parameters' combination on model: 0.8899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.190234</td>\n",
       "      <td>0.024771</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.892418</td>\n",
       "      <td>0.889903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.696155</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.892424</td>\n",
       "      <td>0.889903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.443299</td>\n",
       "      <td>0.024638</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.892424</td>\n",
       "      <td>0.889802</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.574061</td>\n",
       "      <td>0.026436</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.892336</td>\n",
       "      <td>0.889600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.271627</td>\n",
       "      <td>0.025143</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.891208</td>\n",
       "      <td>0.888491</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.501408</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.876680</td>\n",
       "      <td>0.875028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time        params  mean_train_score  \\\n",
       "4      36.190234         0.024771     {'C': 10}          0.892418   \n",
       "5      36.696155         0.024823    {'C': 100}          0.892424   \n",
       "3      37.443299         0.024638      {'C': 1}          0.892424   \n",
       "2      38.574061         0.026436    {'C': 0.1}          0.892336   \n",
       "1      17.271627         0.025143   {'C': 0.01}          0.891208   \n",
       "0       2.501408         0.024842  {'C': 0.001}          0.876680   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "4         0.889903                1  \n",
       "5         0.889903                1  \n",
       "3         0.889802                3  \n",
       "2         0.889600                4  \n",
       "1         0.888491                5  \n",
       "0         0.875028                6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 45.247840347999954 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17632  2126]\n",
      " [ 2137 17770]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89     19758\n",
      "    positive       0.89      0.89      0.89     19907\n",
      "\n",
      "    accuracy                           0.89     39665\n",
      "   macro avg       0.89      0.89      0.89     39665\n",
      "weighted avg       0.89      0.89      0.89     39665\n",
      "\n",
      "\n",
      "accuracy: 0.893\n",
      "f1 score: 0.893\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4366  574]\n",
      " [ 497 4480]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      4940\n",
      "    positive       0.89      0.90      0.89      4977\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n",
      "\n",
      "accuracy: 0.892\n",
      "f1 score: 0.892\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l1', max_iter=500, solver='saga', random_state=random_state)\n",
    "params_log = {\"C\": [0.001,0.01,0.1,1,10,100]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Parameters on Elastic-Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END .......C=0.001;, score=(train=0.887, test=0.884) total time=   6.2s\n",
      "[CV 2/5] END .......C=0.001;, score=(train=0.888, test=0.880) total time=   7.4s\n",
      "[CV 3/5] END .......C=0.001;, score=(train=0.887, test=0.884) total time=   5.8s\n",
      "[CV 4/5] END .......C=0.001;, score=(train=0.885, test=0.887) total time=   6.7s\n",
      "[CV 5/5] END .......C=0.001;, score=(train=0.886, test=0.885) total time=   6.6s\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.893, test=0.889) total time=  21.1s\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.892, test=0.887) total time=  25.4s\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.893, test=0.885) total time=  23.0s\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.892, test=0.891) total time=  25.1s\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.892, test=0.893) total time=  21.6s\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.893, test=0.890) total time=  33.9s\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.893, test=0.888) total time=  32.9s\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.893, test=0.885) total time=  35.7s\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.892, test=0.892) total time=  35.7s\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.892, test=0.893) total time=  33.7s\n",
      "[CV 1/5] END ...........C=1;, score=(train=0.892, test=0.891) total time=  32.6s\n",
      "[CV 2/5] END ...........C=1;, score=(train=0.893, test=0.889) total time=  32.9s\n",
      "[CV 3/5] END ...........C=1;, score=(train=0.893, test=0.885) total time=  32.9s\n",
      "[CV 4/5] END ...........C=1;, score=(train=0.892, test=0.892) total time=  32.6s\n",
      "[CV 5/5] END ...........C=1;, score=(train=0.892, test=0.893) total time=  32.6s\n",
      "[CV 1/5] END ..........C=10;, score=(train=0.892, test=0.891) total time=  32.9s\n",
      "[CV 2/5] END ..........C=10;, score=(train=0.893, test=0.889) total time=  32.9s\n",
      "[CV 3/5] END ..........C=10;, score=(train=0.893, test=0.885) total time=  32.8s\n",
      "[CV 4/5] END ..........C=10;, score=(train=0.892, test=0.892) total time=  32.6s\n",
      "[CV 5/5] END ..........C=10;, score=(train=0.892, test=0.893) total time=  32.7s\n",
      "[CV 1/5] END .........C=100;, score=(train=0.892, test=0.891) total time=  33.7s\n",
      "[CV 2/5] END .........C=100;, score=(train=0.893, test=0.889) total time=  33.1s\n",
      "[CV 3/5] END .........C=100;, score=(train=0.893, test=0.885) total time=  33.1s\n",
      "[CV 4/5] END .........C=100;, score=(train=0.892, test=0.892) total time=  33.8s\n",
      "[CV 5/5] END .........C=100;, score=(train=0.892, test=0.893) total time=  33.7s\n",
      "Training time 860.4526210570002 seconds\n",
      "The best Accuracy of all model parameters' combination on model: 0.8899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.755083</td>\n",
       "      <td>0.025005</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.892424</td>\n",
       "      <td>0.889903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.438301</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.892430</td>\n",
       "      <td>0.889903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.720239</td>\n",
       "      <td>0.025153</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.892437</td>\n",
       "      <td>0.889878</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.366337</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.892468</td>\n",
       "      <td>0.889550</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.232762</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.892103</td>\n",
       "      <td>0.889021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.537566</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.884256</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time        params  mean_train_score  \\\n",
       "4      32.755083         0.025005     {'C': 10}          0.892424   \n",
       "5      33.438301         0.024848    {'C': 100}          0.892430   \n",
       "3      32.720239         0.025153      {'C': 1}          0.892437   \n",
       "2      34.366337         0.025168    {'C': 0.1}          0.892468   \n",
       "1      23.232762         0.024664   {'C': 0.01}          0.892103   \n",
       "0       6.537566         0.024763  {'C': 0.001}          0.886682   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "4         0.889903                1  \n",
       "5         0.889903                1  \n",
       "3         0.889878                3  \n",
       "2         0.889550                4  \n",
       "1         0.889021                5  \n",
       "0         0.884256                6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 41.20970340299937 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17632  2126]\n",
      " [ 2137 17770]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89     19758\n",
      "    positive       0.89      0.89      0.89     19907\n",
      "\n",
      "    accuracy                           0.89     39665\n",
      "   macro avg       0.89      0.89      0.89     39665\n",
      "weighted avg       0.89      0.89      0.89     39665\n",
      "\n",
      "\n",
      "accuracy: 0.893\n",
      "f1 score: 0.893\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4366  574]\n",
      " [ 497 4480]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      4940\n",
      "    positive       0.89      0.90      0.89      4977\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n",
      "\n",
      "accuracy: 0.892\n",
      "f1 score: 0.892\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='elasticnet', max_iter=500, solver='saga', random_state=random_state, l1_ratio=0.5)\n",
    "params_log = {\"C\": [0.001,0.01,0.1,1,10,100]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Parameters on K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .n_neighbors=5;, score=(train=0.887, test=0.821) total time=   7.1s\n",
      "[CV 2/5] END .n_neighbors=5;, score=(train=0.886, test=0.818) total time=   7.2s\n",
      "[CV 3/5] END .n_neighbors=5;, score=(train=0.886, test=0.814) total time=   7.3s\n",
      "[CV 4/5] END .n_neighbors=5;, score=(train=0.883, test=0.822) total time=   7.8s\n",
      "[CV 5/5] END .n_neighbors=5;, score=(train=0.885, test=0.815) total time=   7.4s\n",
      "[CV 1/5] END n_neighbors=25;, score=(train=0.863, test=0.841) total time=   7.4s\n",
      "[CV 2/5] END n_neighbors=25;, score=(train=0.855, test=0.839) total time=   7.5s\n",
      "[CV 3/5] END n_neighbors=25;, score=(train=0.860, test=0.839) total time=   7.7s\n",
      "[CV 4/5] END n_neighbors=25;, score=(train=0.854, test=0.840) total time=   7.6s\n",
      "[CV 5/5] END n_neighbors=25;, score=(train=0.857, test=0.840) total time=   7.4s\n",
      "[CV 1/5] END n_neighbors=50;, score=(train=0.853, test=0.834) total time=   7.3s\n",
      "[CV 2/5] END n_neighbors=50;, score=(train=0.841, test=0.833) total time=   7.5s\n",
      "[CV 3/5] END n_neighbors=50;, score=(train=0.847, test=0.839) total time=   8.6s\n",
      "[CV 4/5] END n_neighbors=50;, score=(train=0.841, test=0.834) total time=   7.6s\n",
      "[CV 5/5] END n_neighbors=50;, score=(train=0.842, test=0.838) total time=   7.3s\n",
      "[CV 1/5] END n_neighbors=75;, score=(train=0.848, test=0.834) total time=   7.7s\n",
      "[CV 2/5] END n_neighbors=75;, score=(train=0.837, test=0.832) total time=   7.6s\n",
      "[CV 3/5] END n_neighbors=75;, score=(train=0.844, test=0.836) total time=   7.9s\n",
      "[CV 4/5] END n_neighbors=75;, score=(train=0.839, test=0.830) total time=   8.5s\n",
      "[CV 5/5] END n_neighbors=75;, score=(train=0.838, test=0.837) total time=   7.9s\n",
      "Training time 766.5807821770013 seconds\n",
      "The best Accuracy of all model parameters' combination on model: 0.8396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040154</td>\n",
       "      <td>7.450882</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>0.857721</td>\n",
       "      <td>0.839581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047819</td>\n",
       "      <td>7.626497</td>\n",
       "      <td>{'n_neighbors': 50}</td>\n",
       "      <td>0.844870</td>\n",
       "      <td>0.835472</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040377</td>\n",
       "      <td>7.874117</td>\n",
       "      <td>{'n_neighbors': 75}</td>\n",
       "      <td>0.841075</td>\n",
       "      <td>0.833934</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045321</td>\n",
       "      <td>7.350121</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.885434</td>\n",
       "      <td>0.818228</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time               params  mean_train_score  \\\n",
       "1       0.040154         7.450882  {'n_neighbors': 25}          0.857721   \n",
       "2       0.047819         7.626497  {'n_neighbors': 50}          0.844870   \n",
       "3       0.040377         7.874117  {'n_neighbors': 75}          0.841075   \n",
       "0       0.045321         7.350121   {'n_neighbors': 5}          0.885434   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "1         0.839581                1  \n",
       "2         0.835472                2  \n",
       "3         0.833934                3  \n",
       "0         0.818228                4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0.03467856600036612 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18058  1700]\n",
      " [ 3805 16102]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87     19758\n",
      "    positive       0.90      0.81      0.85     19907\n",
      "\n",
      "    accuracy                           0.86     39665\n",
      "   macro avg       0.87      0.86      0.86     39665\n",
      "weighted avg       0.87      0.86      0.86     39665\n",
      "\n",
      "\n",
      "accuracy: 0.861\n",
      "f1 score: 0.861\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4451  489]\n",
      " [1008 3969]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.90      0.86      4940\n",
      "    positive       0.89      0.80      0.84      4977\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n",
      "\n",
      "accuracy: 0.849\n",
      "f1 score: 0.849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(weights='uniform')\n",
    "params_log = {\"n_neighbors\": [5, 25, 50, 75]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Parameters on Weighted K-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048548</td>\n",
       "      <td>7.387286</td>\n",
       "      <td>{'n_neighbors': 50}</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049626</td>\n",
       "      <td>7.486418</td>\n",
       "      <td>{'n_neighbors': 100}</td>\n",
       "      <td>0.832648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044284</td>\n",
       "      <td>7.452257</td>\n",
       "      <td>{'n_neighbors': 200}</td>\n",
       "      <td>0.825615</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071878</td>\n",
       "      <td>7.766622</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.818354</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time                params  mean_test_score  \\\n",
       "1       0.048548         7.387286   {'n_neighbors': 50}         0.840691   \n",
       "2       0.049626         7.486418  {'n_neighbors': 100}         0.832648   \n",
       "3       0.044284         7.452257  {'n_neighbors': 200}         0.825615   \n",
       "0       0.071878         7.766622    {'n_neighbors': 5}         0.818354   \n",
       "\n",
       "   rank_test_score  \n",
       "1                1  \n",
       "2                2  \n",
       "3                3  \n",
       "0                4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0.044592282000053274 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19758     0]\n",
      " [    0 19907]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     19758\n",
      "    positive       1.00      1.00      1.00     19907\n",
      "\n",
      "    accuracy                           1.00     39665\n",
      "   macro avg       1.00      1.00      1.00     39665\n",
      "weighted avg       1.00      1.00      1.00     39665\n",
      "\n",
      "\n",
      "accuracy: 1.000\n",
      "f1 score: 1.000\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4505  435]\n",
      " [1067 3910]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86      4940\n",
      "    positive       0.90      0.79      0.84      4977\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n",
      "\n",
      "accuracy: 0.849\n",
      "f1 score: 0.848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(weights='distance')\n",
    "params_log = {\"n_neighbors\": [5, 25, 50, 75]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Paremeters on RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END max_depth=8, n_estimators=100;, score=(train=0.878, test=0.834) total time=   6.2s\n",
      "[CV 2/5] END max_depth=8, n_estimators=100;, score=(train=0.881, test=0.832) total time=   5.4s\n",
      "[CV 3/5] END max_depth=8, n_estimators=100;, score=(train=0.881, test=0.832) total time=   5.7s\n",
      "[CV 4/5] END max_depth=8, n_estimators=100;, score=(train=0.880, test=0.833) total time=   5.7s\n",
      "[CV 5/5] END max_depth=8, n_estimators=100;, score=(train=0.880, test=0.832) total time=   5.6s\n",
      "[CV 1/5] END max_depth=10, n_estimators=100;, score=(train=0.938, test=0.843) total time=   6.9s\n",
      "[CV 2/5] END max_depth=10, n_estimators=100;, score=(train=0.937, test=0.840) total time=   6.7s\n",
      "[CV 3/5] END max_depth=10, n_estimators=100;, score=(train=0.937, test=0.837) total time=   6.7s\n",
      "[CV 4/5] END max_depth=10, n_estimators=100;, score=(train=0.934, test=0.842) total time=   6.7s\n",
      "[CV 5/5] END max_depth=10, n_estimators=100;, score=(train=0.938, test=0.839) total time=   6.7s\n",
      "[CV 1/5] END max_depth=15, n_estimators=100;, score=(train=0.994, test=0.851) total time=   8.9s\n",
      "[CV 2/5] END max_depth=15, n_estimators=100;, score=(train=0.994, test=0.849) total time=   8.8s\n",
      "[CV 3/5] END max_depth=15, n_estimators=100;, score=(train=0.994, test=0.849) total time=   8.9s\n",
      "[CV 4/5] END max_depth=15, n_estimators=100;, score=(train=0.994, test=0.849) total time=  11.6s\n",
      "[CV 5/5] END max_depth=15, n_estimators=100;, score=(train=0.994, test=0.848) total time=  11.5s\n",
      "Training time 130.6357150010008 seconds\n",
      "The best Accuracy of all model parameters' combination on model: 0.8493\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.793211</td>\n",
       "      <td>0.151756</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.994044</td>\n",
       "      <td>0.849263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.633369</td>\n",
       "      <td>0.120893</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.936783</td>\n",
       "      <td>0.840262</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.597806</td>\n",
       "      <td>0.125034</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>0.880108</td>\n",
       "      <td>0.832674</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time                                  params  \\\n",
       "2       9.793211         0.151756  {'max_depth': 15, 'n_estimators': 100}   \n",
       "1       6.633369         0.120893  {'max_depth': 10, 'n_estimators': 100}   \n",
       "0       5.597806         0.125034   {'max_depth': 8, 'n_estimators': 100}   \n",
       "\n",
       "   mean_train_score  mean_test_score  rank_test_score  \n",
       "2          0.994044         0.849263                1  \n",
       "1          0.936783         0.840262                2  \n",
       "0          0.880108         0.832674                3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 15.484404326009098 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19711    47]\n",
      " [  244 19663]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99     19758\n",
      "    positive       1.00      0.99      0.99     19907\n",
      "\n",
      "    accuracy                           0.99     39665\n",
      "   macro avg       0.99      0.99      0.99     39665\n",
      "weighted avg       0.99      0.99      0.99     39665\n",
      "\n",
      "\n",
      "accuracy: 0.993\n",
      "f1 score: 0.993\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4095  845]\n",
      " [ 648 4329]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85      4940\n",
      "    positive       0.84      0.87      0.85      4977\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n",
      "\n",
      "accuracy: 0.849\n",
      "f1 score: 0.849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=core_workers, random_state=random_state)\n",
    "params_log = {\"n_estimators\": [100], 'max_depth': [8, 10, 15]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', n_jobs=None, cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Paremeters on Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ........C=0.06;, score=(train=0.892, test=0.891) total time=  12.4s\n",
      "[CV 2/5] END ........C=0.06;, score=(train=0.893, test=0.889) total time=  12.0s\n",
      "[CV 3/5] END ........C=0.06;, score=(train=0.893, test=0.885) total time=  12.0s\n",
      "[CV 4/5] END ........C=0.06;, score=(train=0.892, test=0.891) total time=  13.3s\n",
      "[CV 5/5] END ........C=0.06;, score=(train=0.892, test=0.893) total time=  13.6s\n",
      "[CV 1/5] END .......C=0.075;, score=(train=0.892, test=0.892) total time=  13.5s\n",
      "[CV 2/5] END .......C=0.075;, score=(train=0.893, test=0.890) total time=  13.0s\n",
      "[CV 3/5] END .......C=0.075;, score=(train=0.893, test=0.886) total time=  12.8s\n",
      "[CV 4/5] END .......C=0.075;, score=(train=0.891, test=0.892) total time=  13.2s\n",
      "[CV 5/5] END .......C=0.075;, score=(train=0.892, test=0.893) total time=  12.9s\n",
      "[CV 1/5] END ........C=0.08;, score=(train=0.892, test=0.891) total time=  13.0s\n",
      "[CV 2/5] END ........C=0.08;, score=(train=0.892, test=0.889) total time=  12.9s\n",
      "[CV 3/5] END ........C=0.08;, score=(train=0.893, test=0.885) total time=  13.0s\n",
      "[CV 4/5] END ........C=0.08;, score=(train=0.892, test=0.890) total time=  14.2s\n",
      "[CV 5/5] END ........C=0.08;, score=(train=0.892, test=0.892) total time=  12.8s\n",
      "Training time 213.09401977499988 seconds\n",
      "The best Accuracy of all model parameters' combination on model: 0.8903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.052503</td>\n",
       "      <td>0.024152</td>\n",
       "      <td>{'C': 0.075}</td>\n",
       "      <td>0.892361</td>\n",
       "      <td>0.890306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.625999</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>{'C': 0.06}</td>\n",
       "      <td>0.892468</td>\n",
       "      <td>0.889853</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.170418</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>{'C': 0.08}</td>\n",
       "      <td>0.892298</td>\n",
       "      <td>0.889600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time        params  mean_train_score  \\\n",
       "1      13.052503         0.024152  {'C': 0.075}          0.892361   \n",
       "0      12.625999         0.024711   {'C': 0.06}          0.892468   \n",
       "2      13.170418         0.024600   {'C': 0.08}          0.892298   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "1         0.890306                1  \n",
       "0         0.889853                2  \n",
       "2         0.889600                3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 16.94387783900015 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17635  2123]\n",
      " [ 2134 17773]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89     19758\n",
      "    positive       0.89      0.89      0.89     19907\n",
      "\n",
      "    accuracy                           0.89     39665\n",
      "   macro avg       0.89      0.89      0.89     39665\n",
      "weighted avg       0.89      0.89      0.89     39665\n",
      "\n",
      "\n",
      "accuracy: 0.893\n",
      "f1 score: 0.893\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4369  571]\n",
      " [ 495 4482]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      4940\n",
      "    positive       0.89      0.90      0.89      4977\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n",
      "\n",
      "accuracy: 0.893\n",
      "f1 score: 0.892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(random_state=random_state)\n",
    "params_log = {\"C\": [0.06, 0.075, 0.08]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', n_jobs=None, cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search for Best Hyper-Paremeters on SVC with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ........C=0.01;, score=(train=0.874, test=0.873) total time= 3.3min\n",
      "[CV 2/5] END ........C=0.01;, score=(train=0.875, test=0.867) total time= 3.9min\n",
      "[CV 3/5] END ........C=0.01;, score=(train=0.875, test=0.869) total time= 3.9min\n",
      "[CV 4/5] END ........C=0.01;, score=(train=0.873, test=0.876) total time= 3.8min\n",
      "[CV 5/5] END ........C=0.01;, score=(train=0.873, test=0.875) total time= 3.7min\n",
      "[CV 1/5] END .........C=0.1;, score=(train=0.902, test=0.890) total time= 2.2min\n",
      "[CV 2/5] END .........C=0.1;, score=(train=0.902, test=0.888) total time= 2.1min\n",
      "[CV 3/5] END .........C=0.1;, score=(train=0.901, test=0.892) total time= 2.1min\n",
      "[CV 4/5] END .........C=0.1;, score=(train=0.900, test=0.894) total time= 1.8min\n",
      "[CV 5/5] END .........C=0.1;, score=(train=0.901, test=0.894) total time= 2.0min\n",
      "[CV 1/5] END ........C=0.75;, score=(train=0.936, test=0.894) total time= 2.6min\n",
      "[CV 2/5] END ........C=0.75;, score=(train=0.936, test=0.889) total time= 2.6min\n",
      "[CV 3/5] END ........C=0.75;, score=(train=0.936, test=0.895) total time= 2.7min\n",
      "[CV 4/5] END ........C=0.75;, score=(train=0.936, test=0.899) total time= 2.7min\n",
      "[CV 5/5] END ........C=0.75;, score=(train=0.935, test=0.897) total time= 2.8min\n",
      "[CV 1/5] END ...........C=1;, score=(train=0.945, test=0.894) total time= 3.1min\n",
      "[CV 2/5] END ...........C=1;, score=(train=0.945, test=0.890) total time= 3.0min\n",
      "[CV 3/5] END ...........C=1;, score=(train=0.944, test=0.894) total time= 2.9min\n",
      "[CV 4/5] END ...........C=1;, score=(train=0.945, test=0.897) total time= 3.2min\n",
      "[CV 5/5] END ...........C=1;, score=(train=0.944, test=0.898) total time= 2.9min\n",
      "[CV 1/5] END ...........C=5;, score=(train=0.994, test=0.883) total time= 8.4min\n",
      "[CV 2/5] END ...........C=5;, score=(train=0.995, test=0.884) total time= 8.0min\n",
      "[CV 3/5] END ...........C=5;, score=(train=0.994, test=0.888) total time= 8.8min\n",
      "[CV 4/5] END ...........C=5;, score=(train=0.994, test=0.892) total time= 8.1min\n",
      "[CV 5/5] END ...........C=5;, score=(train=0.994, test=0.890) total time= 8.1min\n",
      "[CV 1/5] END ..........C=10;, score=(train=0.999, test=0.877) total time=10.4min\n",
      "[CV 2/5] END ..........C=10;, score=(train=1.000, test=0.877) total time=10.3min\n",
      "[CV 3/5] END ..........C=10;, score=(train=1.000, test=0.885) total time=10.5min\n",
      "[CV 4/5] END ..........C=10;, score=(train=1.000, test=0.887) total time=10.6min\n",
      "[CV 5/5] END ..........C=10;, score=(train=1.000, test=0.886) total time=10.5min\n",
      "Training time 12359.811798873998 seconds\n",
      "The best Accuracy of all model parameters' combination on model: 0.8950\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139.382268</td>\n",
       "      <td>20.777007</td>\n",
       "      <td>{'C': 0.75}</td>\n",
       "      <td>0.935718</td>\n",
       "      <td>0.895021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159.507136</td>\n",
       "      <td>21.556002</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.944510</td>\n",
       "      <td>0.894743</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.384619</td>\n",
       "      <td>23.810175</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.901172</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476.175399</td>\n",
       "      <td>20.958608</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>0.994334</td>\n",
       "      <td>0.887079</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>607.349087</td>\n",
       "      <td>22.169286</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.999565</td>\n",
       "      <td>0.882188</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.343035</td>\n",
       "      <td>46.556753</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.873711</td>\n",
       "      <td>0.871751</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time       params  mean_train_score  \\\n",
       "2     139.382268        20.777007  {'C': 0.75}          0.935718   \n",
       "3     159.507136        21.556002     {'C': 1}          0.944510   \n",
       "1      98.384619        23.810175   {'C': 0.1}          0.901172   \n",
       "4     476.175399        20.958608     {'C': 5}          0.994334   \n",
       "5     607.349087        22.169286    {'C': 10}          0.999565   \n",
       "0     175.343035        46.556753  {'C': 0.01}          0.873711   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "2         0.895021                1  \n",
       "3         0.894743                2  \n",
       "1         0.891693                3  \n",
       "4         0.887079                4  \n",
       "5         0.882188                5  \n",
       "0         0.871751                6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 164.07187615699877 seconds\n",
      "Performance of optimized model on training dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18391  1367]\n",
      " [ 1217 18690]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93     19758\n",
      "    positive       0.93      0.94      0.94     19907\n",
      "\n",
      "    accuracy                           0.93     39665\n",
      "   macro avg       0.93      0.93      0.93     39665\n",
      "weighted avg       0.93      0.93      0.93     39665\n",
      "\n",
      "\n",
      "accuracy: 0.935\n",
      "f1 score: 0.935\n",
      "the accuracy of the optimized model on testing dataset...\n",
      "Score on dataset...\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4386  554]\n",
      " [ 449 4528]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90      4940\n",
      "    positive       0.89      0.91      0.90      4977\n",
      "\n",
      "    accuracy                           0.90      9917\n",
      "   macro avg       0.90      0.90      0.90      9917\n",
      "weighted avg       0.90      0.90      0.90      9917\n",
      "\n",
      "\n",
      "accuracy: 0.899\n",
      "f1 score: 0.899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(random_state=random_state)\n",
    "params_log = {\"C\": [0.01, 0.1, 0.75, 1, 5, 10]}\n",
    "\n",
    "grid_log = GridSearchCV(model, param_grid=params_log, scoring='accuracy', cv=5, verbose=4, return_train_score=True)\n",
    "\n",
    "# Train model\n",
    "start = timeit.default_timer()\n",
    "grid_log.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "print(\"The best Accuracy of all model parameters' combination on model: {:.4f}\".format(grid_log.best_score_))\n",
    "\n",
    "display(pd.DataFrame(grid_log.cv_results_).sort_values(by=['rank_test_score'])[['mean_fit_time', 'mean_score_time', \n",
    "                                           'params', 'mean_train_score', 'mean_test_score', 'rank_test_score']])\n",
    "\n",
    "# Retrain on best model\n",
    "best_model = grid_log.best_estimator_\n",
    "start = timeit.default_timer()\n",
    "best_model.fit(train_X, train_y)\n",
    "stop = timeit.default_timer()\n",
    "print('Training time {} seconds'.format(str(stop - start)))\n",
    "\n",
    "# Score on train dataset.\n",
    "print('Performance of optimized model on training dataset...')\n",
    "_, _ = evaluate_model(best_model, train_X, train_y, label_names=None)\n",
    "\n",
    "# Score on test dataset.\n",
    "print(\"the accuracy of the optimized model on testing dataset...\")\n",
    "_, _ = evaluate_model(best_model, test_X, test_y, label_names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_log.cv_results_) \n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "# setting font sizeto 30\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# plotting the line 1 points \n",
    "plt.plot(results['param_C'], results['mean_train_score'], label = \"Mean Train Score\")\n",
    "# plotting the line 2 points \n",
    "plt.plot(results['param_C'], results['mean_test_score'], label = \"Mean Test Score\")\n",
    "plt.xlabel('C')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('Accuracy')\n",
    "# Set a title of the current axes.\n",
    "# plt.title('Two or more lines on same plot with suitable legends ')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x640 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "plot_confusion_matrix(best_model, test_X, test_y)  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
